{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68549992",
   "metadata": {},
   "source": [
    "# Steatosis Segmentation using U-Net\n",
    "Training a U-Net model to segment liver steatosis using the provided Training and Validation datasets.\n",
    "This notebook implements the training pipeline including data loading, model definition, training loop, and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dde62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Configuration\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 20\n",
    "INPUT_SIZE = (256, 256)\n",
    "CHECKPOINT_DIR = 'checkpoints_steatosis'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "# Data paths (Modify these if your folder structure is different)\n",
    "TRAIN_DIR = '/content/SteatosisU-UNet/train'\n",
    "VAL_DIR = '/content/SteatosisU-UNet/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf0e605a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macenko Normalizer Ready.\n"
     ]
    }
   ],
   "source": [
    "# Macenko Generic Implementation using Numpy\n",
    "def macenko_normalize(img, target_means=None, target_stds=None):\n",
    "    \"\"\"\n",
    "    Normalizes an image using Macenko's method.\n",
    "    img: Input image (PIL or numpy array, RGB, uint8)\n",
    "    Returns: Normalized image (numpy array, RGB, uint8)\n",
    "    Reference: http://wwwx.cs.unc.edu/~mn/sites/default/files/macenko2009.pdf\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    HERef = np.array([[0.5626, 0.2159],\n",
    "                      [0.7201, 0.8012],\n",
    "                      [0.4062, 0.5581]])\n",
    "    maxCRef = np.array([1.9705, 1.0308])\n",
    "    \n",
    "    # Defaults if not provided (from a \"good\" standard H&E image)\n",
    "    if target_means is None:\n",
    "        target_means = np.array([0.4853, 0.5655]) # Esempio di medie target\n",
    "    if target_stds is None:\n",
    "        target_stds = np.array([0.1559, 0.1251])  # Esempio di std target\n",
    "\n",
    "    img = np.array(img)\n",
    "    h, w, c = img.shape\n",
    "    \n",
    "    # Reshape and convert to OD\n",
    "    img = img.reshape((-1, 3))\n",
    "    \n",
    "    # Calculate OD (avoid log(0))\n",
    "    OD = -np.log((img.astype(float) + 1) / 240)\n",
    "    \n",
    "    # Remove data with too low OD\n",
    "    ODhat = OD[np.all(OD > 0.15, axis=1)]\n",
    "    \n",
    "    if len(ODhat) < 10:\n",
    "        print(\"Warning: Image mostly background, skipping normalization.\")\n",
    "        return img.reshape(h, w, c)\n",
    "\n",
    "    # Compute eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
    "    \n",
    "    # Project on first two eigenvectors\n",
    "    Vec = eigvecs[:, 1:3] # first two eigenvectors\n",
    "    \n",
    "    # Project data\n",
    "    That = np.dot(ODhat, Vec)\n",
    "    \n",
    "    # Find extreme angles\n",
    "    phi = np.arctan2(That[:, 1], That[:, 0])\n",
    "    minPhi = np.percentile(phi, 1)\n",
    "    maxPhi = np.percentile(phi, 99)\n",
    "    \n",
    "    vMin = np.dot(Vec, np.array([np.cos(minPhi), np.sin(minPhi)]))\n",
    "    vMax = np.dot(Vec, np.array([np.cos(maxPhi), np.sin(maxPhi)]))\n",
    "    \n",
    "    # Heuristic to order Random vectors (H usually first, E second)\n",
    "    if vMin[0] > vMax[0]:\n",
    "        HE = np.array([vMin, vMax])\n",
    "    else:\n",
    "        HE = np.array([vMax, vMin])\n",
    "        \n",
    "    # Rows correspond to channels (RGB), columns to H&E stains\n",
    "    HE = HE.T \n",
    "    \n",
    "    # Unmix stains\n",
    "    Y = np.reshape(OD, (-1, 3)).T\n",
    "    \n",
    "    # Determine concentrations (C)\n",
    "    # C = HE^-1 * Y\n",
    "    # Use pseudo-inverse for stability\n",
    "    C = np.dot(np.linalg.pinv(HE), Y)\n",
    "    \n",
    "    # Normalize concentrations\n",
    "    # We normalize the concentrations to have the same distribution as the reference\n",
    "    # For each stain (row in C)\n",
    "    \n",
    "    # Only normalize valid pixels (OD > 0.15 threshold used earlier for vector finding, \n",
    "    # but here we apply to all. However, stats should be robust)\n",
    "    \n",
    "    # Robust normalization \n",
    "    for i in range(2): # For H and E\n",
    "        c_layer = C[i, :]\n",
    "        # Robust mean/std of this image's stain\n",
    "        # Using percentile to avoid outliers/background\n",
    "        c_valid = c_layer[c_layer > 0.15] # Threshold to ignore background\n",
    "        if len(c_valid) > 0:\n",
    "            q_min, q_max = np.percentile(c_valid, [1, 99])\n",
    "            # Use 99th percentile as max reference is common in Macenko\n",
    "            # But here we want full distribution matching for consistency\n",
    "            \n",
    "            # Simplified approach: Normalize max intensity to target max\n",
    "            # This is the original Macenko step:\n",
    "            C[i, :] *= (maxCRef[i] / (q_max + 1e-7))\n",
    "            \n",
    "            # Alternative: Standard score matching (Reinhard-like on Stains)\n",
    "            # This is often more stable for deep learning\n",
    "            # mu = np.mean(c_valid)\n",
    "            # std = np.std(c_valid)\n",
    "            # C[i, :] = (C[i, :] - mu) * (target_stds[i] / (std + 1e-7)) + target_means[i]\n",
    "\n",
    "    # Recreate image\n",
    "    # OD_rec = HE_ref * C_norm\n",
    "    # Here we typically use the REFERENCE HE vectors if we want to standardize color space completely\n",
    "    # Or use the image's own HE vectors just scaled. \n",
    "    # Macenko standard implies mapping to a target HE matrix.\n",
    "    \n",
    "    # Using Reference HE matrix for full standardization\n",
    "    OD_norm = np.dot(HERef, C)\n",
    "    \n",
    "    # OD to RGB\n",
    "    img_norm = 240 * np.exp(-OD_norm)\n",
    "    img_norm = np.clip(img_norm, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return img_norm.T.reshape(h, w, 3)\n",
    "\n",
    "# Test on a sample image\n",
    "def visualize_normalization_demo(dataset):\n",
    "    idx = np.random.randint(0, len(dataset))\n",
    "    img_path = os.path.join(dataset.image_dir, dataset.images[idx])\n",
    "    \n",
    "    original = Image.open(img_path).convert(\"RGB\")\n",
    "    original_np = np.array(original)\n",
    "    \n",
    "    try:\n",
    "        normalized_np = macenko_normalize(original_np)\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_np)\n",
    "        plt.title(\"Tessuto Originale\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(normalized_np)\n",
    "        plt.title(\"Normalizzazione Macenko\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not normalize: {e}\")\n",
    "\n",
    "print(\"Macenko Normalizer Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f901b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteatosisDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, normalize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with 'image' and 'manual' subdirs.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            normalize (bool): If True, apply Macenko normalization.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = os.path.join(root_dir, 'image')\n",
    "        # Check correct folder\n",
    "        if os.path.exists(os.path.join(root_dir, 'manual_py')):\n",
    "            self.mask_dir = os.path.join(root_dir, 'manual_py')\n",
    "        else:\n",
    "            self.mask_dir = os.path.join(root_dir, 'manual')\n",
    "            print(f\"Warning: 'manual_py' not found in {root_dir}. Using 'manual'.\")\n",
    "\n",
    "        self.transform = transform\n",
    "        self.normalize = normalize\n",
    "        \n",
    "        # Load file lists\n",
    "        valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tif')\n",
    "        self.images = sorted([f for f in os.listdir(self.image_dir) if f.lower().endswith(valid_extensions)])\n",
    "        self.masks = sorted([f for f in os.listdir(self.mask_dir) if f.lower().endswith(valid_extensions)])\n",
    "        \n",
    "        if len(self.images) != len(self.masks):\n",
    "            print(f\"Warning: Mismatch between images and masks in {root_dir}\")\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        mask_name = self.masks[idx] \n",
    "        \n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "        \n",
    "        # Load\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "        \n",
    "        # Apply Normalization BEFORE Transforms (requires numpy)\n",
    "        if self.normalize:\n",
    "            img_np = np.array(image)\n",
    "            try:\n",
    "                # Use default macenko params\n",
    "                norm_np = macenko_normalize(img_np)\n",
    "                image = Image.fromarray(norm_np)\n",
    "            except Exception as e:\n",
    "                # Fallback if SVD fails (empty image etc)\n",
    "                pass\n",
    "\n",
    "        # Transforms\n",
    "        # Resize image\n",
    "        resize_img = transforms.Resize(INPUT_SIZE, interpolation=transforms.InterpolationMode.BILINEAR)\n",
    "        image = resize_img(image)\n",
    "        \n",
    "        # Resize mask\n",
    "        # IMPORTANT: Nearest Neighbor for masks\n",
    "        resize_mask = transforms.Resize(INPUT_SIZE, interpolation=transforms.InterpolationMode.NEAREST)\n",
    "        mask = resize_mask(mask)\n",
    "        \n",
    "        # ToTensor\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        image = to_tensor(image)\n",
    "        mask_t = to_tensor(mask)\n",
    "        \n",
    "        # Binarize Mask (Hard threshold 0)\n",
    "        # Assuming manual_py is 0/1 or 0/255.\n",
    "        mask_t = (mask_t > 0).float()\n",
    "        \n",
    "        return image, mask_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c069690e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets with Macenko Normalization...\n",
      "Warning: 'manual_py' not found in train. Using 'manual'.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train/image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-620067309.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create Dataset instances with Normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing Datasets with Macenko Normalization...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSteatosisDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSteatosisDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-632170009.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, transform, normalize)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# Load file lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mvalid_extensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.bmp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_extensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_extensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/image'"
     ]
    }
   ],
   "source": [
    "# Create Dataset instances with Normalization\n",
    "print(\"Initializing Datasets with Macenko Normalization...\")\n",
    "train_dataset = SteatosisDataset(TRAIN_DIR, normalize=True)\n",
    "val_dataset = SteatosisDataset(VAL_DIR, normalize=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "print(\"Creating DataLoaders...\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0) # Workers=0 safer for complex numpy ops in getitem\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Training set: {len(train_dataset)} images\")\n",
    "print(f\"Validation set: {len(val_dataset)} images\")\n",
    "\n",
    "# SHOW NORMALIZATION EFFECT\n",
    "print(\"\\n--- Visualizing Normalization Effect (Train Set) ---\")\n",
    "visualize_normalization_demo(train_dataset)\n",
    "print(\"---------------------------------------------------\\n\")\n",
    "\n",
    "# Sanity check: Visualize one sample from loader\n",
    "temp_img, temp_mask = train_dataset[0]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(temp_img.permute(1, 2, 0))\n",
    "plt.title(f\"Normalized Input (Tensor)\\nRange: [{temp_img.min():.2f}, {temp_img.max():.2f}]\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(temp_mask.squeeze(), cmap='gray')\n",
    "plt.title(f\"Mask\\nUnique: {torch.unique(temp_mask).tolist()}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Applies two consecutive conv-batchnorm-relu layers\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels=3,\n",
    "                 out_channels=1,\n",
    "                 init_filters=64,\n",
    "                 depth=4,\n",
    "                 bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.down_layers = nn.ModuleList()\n",
    "        self.up_layers = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # Encoder\n",
    "        filters = init_filters\n",
    "        for d in range(depth):\n",
    "            conv = DoubleConv(in_channels, filters)\n",
    "            self.down_layers.append(conv)\n",
    "            in_channels = filters\n",
    "            filters *= 2\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(in_channels, filters)\n",
    "\n",
    "        # Decoder\n",
    "        for d in range(depth):\n",
    "            filters //= 2\n",
    "            if bilinear:\n",
    "                up = nn.Sequential(\n",
    "                    nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "                    nn.Conv2d(filters * 2, filters, kernel_size=1)\n",
    "                )\n",
    "            else:\n",
    "                up = nn.ConvTranspose2d(filters * 2, filters, kernel_size=2, stride=2)\n",
    "            self.up_layers.append(nn.ModuleDict({\n",
    "                'up': up,\n",
    "                'conv': DoubleConv(filters * 2, filters)\n",
    "            }))\n",
    "\n",
    "        # Output layer\n",
    "        self.out_conv = nn.Conv2d(init_filters, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        for down in self.down_layers:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            skip = skip_connections[-(i+1)]\n",
    "            up = self.up_layers[i]['up'](x)\n",
    "            if up.size() != skip.size():\n",
    "                # Resize in case of odd size mismatch\n",
    "                up = F.interpolate(up, size=skip.shape[2:])\n",
    "            x = torch.cat([skip, up], dim=1)\n",
    "            x = self.up_layers[i]['conv'](x)\n",
    "\n",
    "        return self.out_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8c0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Functions\n",
    "def compute_batch_stats(pred_logits, target_mask):\n",
    "    \"\"\"\n",
    "    Calculates statistics for a batch to compute:\n",
    "    1. Dice Standard (Mean per Image)\n",
    "    2. Dice Strict (Mean per Image)\n",
    "    3. Global Stats (Intersection & Union) for Batch-Based/Global Dice\n",
    "    \"\"\"\n",
    "    # Sigmoid & Binarization\n",
    "    probs = torch.sigmoid(pred_logits)\n",
    "    pred = (probs > 0.5).float()\n",
    "    \n",
    "    # Flatten: (B, C, H, W) -> (B, -1)\n",
    "    pred_flat = pred.view(pred.size(0), -1)\n",
    "    target_flat = target_mask.view(target_mask.size(0), -1)\n",
    "    \n",
    "    # Intersection & Sum per image\n",
    "    intersection = (pred_flat * target_flat).sum(dim=1)\n",
    "    union_raw = pred_flat.sum(dim=1) + target_flat.sum(dim=1)\n",
    "    \n",
    "    # --- 1. Dice Standard Per Image (with smooth) ---\n",
    "    smooth = 1e-5\n",
    "    dice_std_img = (2. * intersection + smooth) / (union_raw + smooth)\n",
    "    \n",
    "    # --- 2. Dice Strict Per Image (no smooth, handle empty) ---\n",
    "    # If both empty (union=0) -> 1.0, Else calc dice.\n",
    "    dice_strict_img = torch.zeros_like(intersection)\n",
    "    \n",
    "    is_empty = (union_raw == 0)\n",
    "    # Case both empty -> 1\n",
    "    dice_strict_img[is_empty] = 1.0 \n",
    "    # Case not empty -> 2*I / U\n",
    "    if (~is_empty).any():\n",
    "        dice_strict_img[~is_empty] = (2. * intersection[~is_empty]) / union_raw[~is_empty]\n",
    "\n",
    "    # --- 3. For Global/Batch Calculation ---\n",
    "    total_intersection = intersection.sum().item()\n",
    "    total_union = union_raw.sum().item()\n",
    "    \n",
    "    return {\n",
    "        'sum_dice_std': dice_std_img.sum().item(),\n",
    "        'sum_dice_strict': dice_strict_img.sum().item(),\n",
    "        'total_int': total_intersection,\n",
    "        'total_union': total_union,\n",
    "        'n_samples': pred.size(0)\n",
    "    }\n",
    "\n",
    "# Initialize Model\n",
    "model = UNet(in_channels=3, out_channels=1, init_filters=32, depth=4).to(device)\n",
    "\n",
    "# Loss Function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"Model initialized with detailed metric tracking.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# History storage\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_dice_std_avg': [], 'val_dice_std_avg': [],\n",
    "    'train_dice_strict_avg': [], 'val_dice_strict_avg': [],\n",
    "    'train_dice_std_global': [], 'val_dice_std_global': [],\n",
    "    'train_dice_strict_global': [], 'val_dice_strict_global': []\n",
    "}\n",
    "\n",
    "best_metric = 0.0\n",
    "\n",
    "print(f\"Starting training for {NUM_EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- TRAINING ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Accumulators for metrics\n",
    "    train_stats = {'sum_dice_std': 0, 'sum_dice_strict': 0, 'total_int': 0, 'total_union': 0, 'n_samples': 0}\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Train', leave=False)\n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Calculate stats for this batch\n",
    "        with torch.no_grad():\n",
    "            batch_s = compute_batch_stats(outputs, masks)\n",
    "            for k in train_stats:\n",
    "                train_stats[k] += batch_s[k]\n",
    "                \n",
    "    # End of Train Epoch Calculations\n",
    "    epoch_train_loss = running_loss / len(train_dataset)\n",
    "    \n",
    "    # Train Metrics\n",
    "    t_dice_std_avg = train_stats['sum_dice_std'] / train_stats['n_samples']\n",
    "    t_dice_strict_avg = train_stats['sum_dice_strict'] / train_stats['n_samples']\n",
    "    \n",
    "    # Global Train Metrics\n",
    "    smooth = 1e-5\n",
    "    t_dice_std_global = (2. * train_stats['total_int'] + smooth) / (train_stats['total_union'] + smooth)\n",
    "    \n",
    "    if train_stats['total_union'] == 0:\n",
    "         # If the whole dataset was empty? Unlikely, but let's handle.\n",
    "         # If int is also 0 -> 1.\n",
    "         t_dice_strict_global = 1.0 if train_stats['total_int'] == 0 else 0.0\n",
    "    else:\n",
    "         t_dice_strict_global = (2. * train_stats['total_int']) / train_stats['total_union']\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    val_stats = {'sum_dice_std': 0, 'sum_dice_strict': 0, 'total_int': 0, 'total_union': 0, 'n_samples': 0}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Val', leave=False):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            running_val_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            batch_s = compute_batch_stats(outputs, masks)\n",
    "            for k in val_stats:\n",
    "                val_stats[k] += batch_s[k]\n",
    "\n",
    "    # End of Val Epoch Calculations\n",
    "    epoch_val_loss = running_val_loss / len(val_dataset)\n",
    "    \n",
    "    # Val Metrics\n",
    "    v_dice_std_avg = val_stats['sum_dice_std'] / val_stats['n_samples']\n",
    "    v_dice_strict_avg = val_stats['sum_dice_strict'] / val_stats['n_samples']\n",
    "    \n",
    "    # Global Val Metrics\n",
    "    v_dice_std_global = (2. * val_stats['total_int'] + smooth) / (val_stats['total_union'] + smooth)\n",
    "    \n",
    "    if val_stats['total_union'] == 0:\n",
    "         v_dice_strict_global = 1.0 if val_stats['total_int'] == 0 else 0.0\n",
    "    else:\n",
    "         v_dice_strict_global = (2. * val_stats['total_int']) / val_stats['total_union']\n",
    "\n",
    "    # Update History\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['train_dice_std_avg'].append(t_dice_std_avg)\n",
    "    history['val_dice_std_avg'].append(v_dice_std_avg)\n",
    "    history['train_dice_strict_avg'].append(t_dice_strict_avg)\n",
    "    history['val_dice_strict_avg'].append(v_dice_strict_avg)\n",
    "    history['train_dice_std_global'].append(t_dice_std_global)\n",
    "    history['val_dice_std_global'].append(v_dice_std_global)\n",
    "    history['train_dice_strict_global'].append(t_dice_strict_global)\n",
    "    history['val_dice_strict_global'].append(v_dice_strict_global)\n",
    "\n",
    "    # Print Report\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: T={epoch_train_loss:.4f} V={epoch_val_loss:.4f}\")\n",
    "    print(f\"   [Per-Image]  Dice Strict: T={t_dice_strict_avg:.4f} V={v_dice_strict_avg:.4f} | Std: T={t_dice_std_avg:.4f} V={v_dice_std_avg:.4f}\")\n",
    "    print(f\"   [Batch-Based] Dice Strict: T={t_dice_strict_global:.4f} V={v_dice_strict_global:.4f} | Std: T={t_dice_std_global:.4f} V={v_dice_std_global:.4f}\")\n",
    "\n",
    "    # Save Checkpoints\n",
    "    current_metric = v_dice_strict_avg  # Use Per-Image Strict Dice as main criteria\n",
    "    if current_metric > best_metric:\n",
    "        best_metric = current_metric\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "        print(f\"   --> NEW BEST MODEL (Dice Strict Avg: {best_metric:.4f})\")\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), os.path.join(CHECKPOINT_DIR, f'model_epoch_{epoch+1}.pth'))\n",
    "\n",
    "# Save final params\n",
    "params = {\n",
    "    \"config\": {\"batch_size\": BATCH_SIZE, \"epochs\": NUM_EPOCHS, \"input_size\": INPUT_SIZE},\n",
    "    \"results\": {\n",
    "        \"best_val_dice_strict_avg\": best_metric,\n",
    "        \"final_val_dice_strict_global\": v_dice_strict_global\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(CHECKPOINT_DIR, 'training_results.json'), 'w') as f:\n",
    "    json.dump(params, f, indent=4)\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0667b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Comprehensive Metrics\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Losses\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss', marker='.')\n",
    "plt.plot(history['val_loss'], label='Val Loss', marker='.')\n",
    "plt.title('BCE Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 2. Strict Dice (Per Image - The main metric)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history['train_dice_strict_avg'], label='Train Strict (Avg)', marker='.')\n",
    "plt.plot(history['val_dice_strict_avg'], label='Val Strict (Avg)', marker='.')\n",
    "plt.title('Dice Strict (Per-Image Average)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 3. Global vs Average Comparison (Validation Only)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history['val_dice_strict_avg'], label='Val Strict (Avg)', marker='.', linestyle='--')\n",
    "plt.plot(history['val_dice_strict_global'], label='Val Strict (Global)', marker='.')\n",
    "plt.title('Validation: Average vs Global (Strict)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# 4. Standard vs Strict Comparison (Validation Only)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(history['val_dice_std_avg'], label='Val Standard (Avg)', marker='.', linestyle='--')\n",
    "plt.plot(history['val_dice_strict_avg'], label='Val Strict (Avg)', marker='.')\n",
    "plt.title('Validation: Standard vs Strict (Average)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Visualization of Predictions (Best Model) ---\n",
    "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pth')))\n",
    "model.eval()\n",
    "\n",
    "# Get a batch\n",
    "images, masks = next(iter(val_loader))\n",
    "images = images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    preds = torch.sigmoid(outputs) > 0.5 \n",
    "\n",
    "# Plot\n",
    "n_plot = min(3, images.size(0))\n",
    "fig, axs = plt.subplots(n_plot, 3, figsize=(15, 5*n_plot))\n",
    "\n",
    "images_np = images.cpu().permute(0, 2, 3, 1).numpy()\n",
    "masks_np = masks.cpu().squeeze().numpy()\n",
    "preds_np = preds.float().cpu().squeeze().numpy()\n",
    "\n",
    "if n_plot == 1: axs = [axs] # Handle single case\n",
    "\n",
    "for i in range(n_plot):\n",
    "    # Original\n",
    "    axs[i][0].imshow(images_np[i])\n",
    "    axs[i][0].set_title(f\"Image {i+1}\")\n",
    "    axs[i][0].axis('off')\n",
    "    \n",
    "    # Ground Truth\n",
    "    axs[i][1].imshow(masks_np[i], cmap='gray', vmin=0, vmax=1)\n",
    "    axs[i][1].set_title(\"Ground Truth (Manual)\")\n",
    "    axs[i][1].axis('off')\n",
    "    \n",
    "    # Prediction\n",
    "    axs[i][2].imshow(preds_np[i], cmap='gray', vmin=0, vmax=1)\n",
    "    axs[i][2].set_title(\"Prediction (U-Net)\")\n",
    "    axs[i][2].axis('off')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b72b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# VISUALIZZAZIONE E SALVATAGGIO DI TUTTE LE PREDIZIONI DEL VALIDATION SET\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "OUTPUT_DIR = 'val_predictions_output'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Carichiamo il modello migliore assoluto\n",
    "print(\"Caricamento del modello migliore...\")\n",
    "model.load_state_dict(torch.load(os.path.join(CHECKPOINT_DIR, 'best_model.pth')))\n",
    "model.eval()\n",
    "\n",
    "# Liste per lo storage temporaneo dei dati da plottare\n",
    "plot_data = []\n",
    "\n",
    "print(f\"Salvataggio maschere in: {os.path.abspath(OUTPUT_DIR)}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Iteriamo direttamente sul dataset per avere accesso facile ai nomi dei file originali\n",
    "    # Nota: val_dataset.images contiene la lista dei nomi dei file\n",
    "    for i in range(len(val_dataset)):\n",
    "        \n",
    "        # Recuperiamo i dati dal dataset\n",
    "        img_tensor, mask_tensor = val_dataset[i]\n",
    "        filename = val_dataset.images[i]\n",
    "        \n",
    "        # Preparazione input per la rete (aggiungiamo dimensione batch: [1, 3, 256, 256])\n",
    "        img_input = img_tensor.unsqueeze(0).to(device)\n",
    "        \n",
    "        # INFERENCE\n",
    "        output = model(img_input)\n",
    "        \n",
    "        # Post-processing: Sigmoide -> Soglia 0.5 -> float\n",
    "        pred_prob = torch.sigmoid(output)\n",
    "        pred_mask = (pred_prob > 0.5).float().cpu().squeeze().numpy() # [256, 256]\n",
    "        \n",
    "        # Recuperiamo la ground truth per il plot\n",
    "        gt_mask = mask_tensor.squeeze().numpy() # [256, 256]\n",
    "        \n",
    "        # Recuperiamo l'immagine originale per il plot (da tensore a numpy HWC)\n",
    "        orig_img = img_tensor.permute(1, 2, 0).numpy()\n",
    "        \n",
    "        # --- SALVATAGGIO SU DISCO ---\n",
    "        # Convertiamo la maschera da 0.0-1.0 a 0-255 uint8 per salvarla come immagine visibile\n",
    "        pred_img_pil = Image.fromarray((pred_mask * 255).astype(np.uint8))\n",
    "        save_path = os.path.join(OUTPUT_DIR, filename)\n",
    "        pred_img_pil.save(save_path)\n",
    "        \n",
    "        # Aggiungiamo alla lista per il plot finale\n",
    "        plot_data.append({\n",
    "            'filename': filename,\n",
    "            'orig': orig_img,\n",
    "            'gt': gt_mask,\n",
    "            'pred': pred_mask\n",
    "        })\n",
    "\n",
    "print(f\"Generate {len(plot_data)} maschere.\")\n",
    "\n",
    "# --- PLOT DI TUTTE LE IMMAGINI ---\n",
    "# Attenzione: se il validation set è enorme, questa immagine sarà molto alta verticale.\n",
    "num_samples = len(plot_data)\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "print(\"Generazione grafico comparativo...\")\n",
    "\n",
    "# Gestione caso speciale se c'è solo 1 immagine nel validation set\n",
    "if num_samples == 1:\n",
    "    axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "for idx, data in enumerate(plot_data):\n",
    "    # Colonna 1: Immagine Originale\n",
    "    axes[idx, 0].imshow(data['orig'])\n",
    "    axes[idx, 0].set_title(f\"Orig: {data['filename']}\")\n",
    "    axes[idx, 0].axis('off')\n",
    "    \n",
    "    # Colonna 2: Maschera Manuale (Ground Truth)\n",
    "    axes[idx, 1].imshow(data['gt'], cmap='gray')\n",
    "    axes[idx, 1].set_title(\"Manual (Verità)\")\n",
    "    axes[idx, 1].axis('off')\n",
    "    \n",
    "    # Colonna 3: Maschera Predetta dalla U-Net\n",
    "    axes[idx, 2].imshow(data['pred'], cmap='gray')\n",
    "    axes[idx, 2].set_title(\"Predizione U-Net\")\n",
    "    axes[idx, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
